<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>LSTM Word Prediction from Scratch | Phuoc H. Bui</title> <meta name="author" content="Phuoc H. Bui"> <meta name="description" content="This is a documentation for our work on constructing an LSTM net-work that uses only Numpy for word prediction. In our work, we use previous two words to predict a next word. The formulas and structure of our program are described in detail in this documentation."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="phuoc-bui.github.io/blog/2023/math/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "LSTM Word Prediction from Scratch",
      "description": "This is a documentation for our work on constructing an LSTM net-work that uses only Numpy for word prediction. In our work, we use previous two words to predict a next word. The formulas and structure of our program are described in detail in this documentation.",
      "published": "November 1, 2023",
      "authors": [
        {
          "author": "Phuoc Bui",
          "authorURL": "https://phuoc-bui.github.io",
          "affiliations": [
            {
              "name": "Chidoanh",
              "url": ""
            }
          ]
        },
        {
          "author": "Thuong Dang",
          "authorURL": "https://en.wikipedia.org/wiki/Boris_Podolsky",
          "affiliations": [
            {
              "name": "IAS, Princeton",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Phuoc </span>H. Bui</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>LSTM Word Prediction from Scratch</h1> <p>This is a documentation for our work on constructing an LSTM net-work that uses only Numpy for word prediction. In our work, we use previous two words to predict a next word. The formulas and structure of our program are described in detail in this documentation.</p> </d-title><d-byline></d-byline><d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#lstm-architecture">LSTM architecture</a></div> <div><a href="#forward-method">Forward method</a></div> <div><a href="#backward-method">Backward method</a></div> <div><a href="#experiment">Experiment</a></div> </nav> </d-contents> <d-cite key="gregor2015draw"></d-cite> <h2 id="lstm-architecture">LSTM architecture</h2> <p>In short, LSTM is a variant of RNN, and it has <em>memory cells</em> and it <em>learns to forget</em>. That means, at each step, we will forget unimportant information and memorize important information. Let us look at the architecture of LSTM.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lstm/LSTM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lstm/LSTM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lstm/LSTM-1400.webp"></source> <img src="/assets/img/lstm/LSTM.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> [1] LSTM cell internal structure. </div> <p>The picture is taken from [1]. For each block of an LSTM network, there will be four gates: a forget gate, an input gate, an output gate, and an intermediate gate, and their values are denoted $f_t, i_t, o_t, \tilde{c_t}$, respectively. We also denote $c_t$ the internal memory state, and $h_t$ the hidden state as in the architecture of RNN. Let us take a explain a bit further on this gated architecture. For the inputs, we denote</p> <p>$h_{t-1}$: the previous hidden state.</p> <p>$s_t = W_{_} x_t + b_{_}$: where $W_{_}$ and $b_{_}$ denote the weight and bias for gate $_$.</p> <p>$c_{t-1}$: the previous memory cell.</p> <p>For gates, we have</p> <p><strong>Forget gate.</strong> As we can see, the output of the forget gate $f_t$ has inputs $h_{t-1}$ and $s_t$, where $s_t = W_f x_t + b_f$. Those are weight bias for the forget gate. And</p> <p>\(f_t = \sigma(U_f h_{t-1} + W_f x_t + b_f),\) where $\sigma$ is the sigmoid function, $U_f$ is the weight for the forget gate of $h_{t-1}$.</p> <p><strong>Input gate.</strong> The output of the input gate, denoted $i_t$ has inputs $h_{t-1}$ and $s_t$, where $s_t = W_i x_t + b_i$. Those are weight and bias for the input gate. And</p> <p>\(i_t = \sigma(U_i h_{t-1} + W_i x_t + b_i),\) where $U_i$ is the weight of $h_{t-1}$ for the input gate.</p> <p><strong>Output gate.</strong> Similarly, we have \(o_t = \sigma(U_i h_{t-1} + W_o x_t + b_o)\)</p> <p><strong>Intermediate gate.</strong> We have \(\tilde{c_t} = \tanh(U_c h_{t-1} + W_c x_t + b_c)\) Through gates, we can define our memory cell \(c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c_t},\)</p> <p>where $\odot$ denotes the Hadamard product, i.e. it is element-wise multiplication of matrices. Let us explain a bit about this. Our $f_t$ is defined as a sigmoid function of previous state and current input, and its range is between $0$ and $1$. With Hadamard product, if a value $f_{ij}$ of $f_t$ is very close to $0$, then \((c_{t-1})_{ij}f_{ij}\) is also very close to zero, and it means, the value of this position is not very important we can forget it. On the other hand, the product $i_t \odot \tilde{c_t}$ decides which information will be updated. Why? Because if a value $i_{jk}$ of $i_t$ is very close to $1$, then \((i_t \odot \tilde {c_t})_{jk}\) is very close $(\tilde{c_t})_{jk}$. In some variants of LSTM, $i_t$ is replaced by $(1 - f_t)$. In short, $c_t$ helps us filter information: it determines which information we should forget or remember.</p> <p>Now, we can update our current hidden state \(h_t = \tanh(c_t) \odot o_t\)</p> <p>And again, we see a filter $o_t$ here: it decides which information to pass through. To produce an output, we can again use softmax</p> <p>\(\widehat{y} = \operatorname{softmax}(W_y h_n + b_y),\) where $h_n$ is the last hidden state.</p> <h2 id="forward-method">Forward method</h2> <p>In the forward method, we initialized - random matrices $U_f, W_f, U_i, W_i, U_c, W_c, U_o, W_o$ and - random vectors $b_f, b_i, b_c, b_o$ for the four gates. Moreover, we will also initialize randomly the weight $W_y$ and the bias $b_y$ for the output. Their sizes depend on our input size, output size and a chosen hidden size. In our case, we set input size and output size to be the size of our dictionary, and hidden size 64.</p> <p>Note that, because of the LSTM architecture, we will need to add the zero vector $h_0$ and $c_0$ for the initialized hidden state and memory cell. Because we will start from time $t=1$, and the length of hidden states and gates are the same, it is easier if we also set those vectors $f_0, i_0, \tilde{c_0}, o_0$ to be zero (we never use them though). Now, we can easily code the forward method based on the formulas above. Here are the codes</p> <p>Our dataset is very simple because of limited resources. It consists of 40 random sentences generated by chatGPT. Our task is to predict a word based on two previous words.</p> <p>First, we created a dictionary consisting of all words in our dataset. With each sentence, we created pairs of inputs and outputs, where the inputs are two consecutive words, and outputs are the third consecutive words. For example, if we have a sentence “I am so happy”, then there will be two pairs $X_0 = \text{“i am”}, y_0 = \text{“so”}$, and $X_1 = \text{“am so”}, y_1 = \text{“happy”}$.</p> <p>We then transformed pairs into one-hot-encoded vectors, whose lengths are equal to the size of our dictionary. Of course there are other methods for word embeddings, such as word2vec or GloVe but it is not our main purposes. That’s why we keep it simple.</p> <p>Here are the results of our model</p> <p>As we can see, the results is quite low because of the following reasons:</p> <ul> <li>The dataset consists of random sentences and does not have a specific context.</li> <li>The size of the dataset is very small.</li> <li>The word prediction task is hard, especially with two or more words.</li> <li>The program is for educational purpose.</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"phuoc-bui/phuoc-bui.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Phuoc H. Bui. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>